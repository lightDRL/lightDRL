# for mobile avoidance
conn: 
    server_worker_num: &ref_server_worker_num 1
    server_ip: 127.0.0.1
    server_frontend_port: 5555
    server_backend_port: 5556
    client_num: 4
    client_retries: 3
    client_timeout: 2500   #ms

RL:
    method: 'DDPG'
    state_frames: 1
    state_shape: 22
    action_discrete: yes         # no -> provide action_bound for continuous control
    action_num: 1               # if action_discrete, this will be ONEHOT. No shape support, what need for action shape?
    action_bound: [-3.14159, 3.14159]
    reward_discount: 0.9
    train_multi_steps: yes      # sub choose, train_if_down, train_run_steps,            
    train_if_down: yes
    reward_reverse_norm: yes
    
DDPG:
    lr_actor: 0.001  # learning rate for actor (1e-4)
    lr_critic: 0.002  # learning rate for critic
    exp_decay: 0.01
    memory_capacity: 1000
    batch_size: 32
    


misc:
    output_tf: yes
    output_tf_dir: './log'
    model_save_cycle: 3
    gpu_memory_ratio: 0.3
    