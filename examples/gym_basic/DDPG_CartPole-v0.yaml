conn: 
    server_worker_num: &ref_server_worker_num 1
    server_ip: 127.0.0.1
    server_frontend_port: 5555
    server_backend_port: 5556
    client_num: 4
    client_retries: 3
    client_timeout: 2500   #ms

RL:
    method: 'DDPG'
    # train_multi_steps: 1       # default: 1, param: 'if_down', 'steps(int)'-> train if down or train after steps    
    reward_gamma: 0.99
    reward_factor: 0.01            # default: 1
    reward_reverse: yes           # dafault: False
    add_data_steps: 'if_down'     # dafault: 1 , param: 'if_down', 'steps(int)'    
    exploration: 300        # train after exploration step
    action_noise: 'Uhlenbeck'

DDPG:
    lr_actor:  0.0001  # learning rate for actor (1e-4)
    lr_critic:  0.001  # learning rate for critic
    memory_capacity: 5000
    memory_train_min: 300 
    batch_size: 100          
    tau: 0.001              # the factor about update network with target network
    
Uhlenbeck:   # Noise parameters - Ornstein Uhlenbeck
    max_ep: 500
    delta: 0.5  # The rate of change (time)
    sigma: 0.5  # Volatility of the stochastic processes
    ou_a: 3.0   # The rate of mean reversion
    ou_mu: 0.0

actor_NN:
    actor_fc_1: # use default op:'relu' and initializer: 'truncated_normal'
        type: 'fc'
        size: 400
        bias_const: 0.03

    actor_fc_2:
        type: 'fc'
        size: 300
        bias_const: 0.03

critic_state_NN:
    state_fc_1: # use default op:'relu' and initializer: 'truncated_normal'
        type: 'fc'
        size: 400
        bias_const: 0.03

    state_fc_2:
        type: 'fc'
        size: 300
        bias_const: 0.03
        op: 'none'


critic_action_NN:
    action_fc_1: # use default op:'relu' and initializer: 'truncated_normal'
        type: 'fc'
        size: 300
        bias_const: 0.03
        op: 'none'
        
misc:
    model_save_cycle: 100
    model_retrain: yes
    gpu_memory_ratio: 0.3
    random_seed: 82             # t_82 get max reward = 114.10
    max_ep:  50                       # defualt:1000, over the ep will auto exit()
    render: yes                        # defualt: false, render the env 
    render_after_ep: 100                # defualt: 0, render afet the ep 
    gym_env: 'CartPole-v0'
    gym_monitor_path: 'monitor/'        # will crate in data_pool/<project_name>/monitor/
    gym_monitor_episode: 50             # record every 10 episode 
    redirect_stdout_2_file: no