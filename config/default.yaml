conn: 
    server_worker_num: &ref_server_worker_num 4
    server_ip: 127.0.0.1
    server_frontend_port: 5555
    server_backend_port: 5556
    client_num: 4
    client_retries: 3
    client_timeout: 2500   #ms

RL:
    method: 'A3C'
    state_frames: 1
    state_shape: !!python/tuple [7,]
    action_discrete: no         # no -> provide action_bound for continuous
    action_num: 2
    action_bound: [-1,1]
    train_run_steps: 5


# NOTE about action:
# ------Discrete--------#
#   action_discrete: yes
#   action_num: 3
#       predict action shape: (1,)  -> (0, 1, 2)
# ------Continuous--------#
#   action_discrete: yes
#   action_num: 2
#   action_bound: [-1,1] 
#       predict action shape: (2,)  -> ( 0: [-1, 1] , 1: [-1,1])

A3C:
    LR_A: 0.0001  # learning rate for actor (1e-4)
    LR_C: 0.0002  # learning rate for critic
    GAMMA: 0.9  # reward discount
    ENTROPY_BETA: 0.01
    main_net_scope: 'Main_Net'
    worker_num: *ref_server_worker_num # refer to server_worker_num

log:
    output_tf: yes
    output_tf_dir: './log'
    